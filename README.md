ğŸ“š Wikipedia Question Answering System

A retrieval-augmented question answering (RAG) system that uses Wikipedia as a knowledge source, semantic vector search for retrieval, and Transformer-based models for answer extraction.

ğŸ§© Description

This project implements an end-to-end pipeline that retrieves relevant Wikipedia passages using dense embeddings and FAISS, then extracts accurate answers using a pre-trained question-answering model.

âš™ï¸ Core Components

ğŸ“„ Document Ingestion: Wikipedia content retrieval

ğŸ§  Embedding Layer: Sentence Transformers

ğŸ” Vector Store: FAISS for similarity search

ğŸ¤– Inference Layer: Hugging Face Transformer QA model

ğŸ› ï¸ Technology Stack

ğŸ Python

ğŸŒ Wikipedia API

ğŸ§¬ Sentence-Transformers

âš¡ FAISS (CPU)

ğŸ¤— Hugging Face Transformers

ğŸ”¥ PyTorch, NumPy

ğŸš€ Setup
pip install wikipedia faiss-cpu transformers sentence-transformers torch numpy


ğŸ”„ Restart the runtime after installing dependencies.

â–¶ï¸ Example Usage
query = "What is machine learning?"
response = qa_pipeline(query)
print(response)

ğŸ”„ System Flow

ğŸ“¥ Fetch and preprocess Wikipedia documents

âœ‚ï¸ Split text into manageable chunks

ğŸ§  Generate vector embeddings

ğŸ” Retrieve top-matching passages via FAISS

âœ… Extract answers using a QA model

ğŸ“Œ Design Notes

Clean, modular, and easy to extend

Runs fully on CPU by default

âš ï¸ Triton-related warnings do not impact functionality

ğŸ—ºï¸ Roadmap

â• Multiple data source support

ğŸš€ GPU-accelerated indexing

ğŸ§­ Advanced retrieval strategies (HNSW, IVF)

âœ¨ LLM-based generative answering
